\chapter{Conclusioni e sviluppi futuri}

\section{Conclusioni}

I maggiori punti di criticità del progetto risiedevano, come prevedibile, nell'utilizzo della rete neurale su dispositivo
Android. La conversione del modello Pytorch originale ad un modello utilizzabile su Android ha richiesto la reimplementazione
di alcune componenti software data la complessità del modello.

Altro punto critico è stata la coordinazione e comunicazione tra i diversi processi in gioco nell'applicazione, dovendo
integrare la valutazione eseguita dalla rete neurale con un'interfaccia grafica il più possibile user-friendly.
Come accennato brevemente, i test svolti sull'applicazione hanno dato luogo a tempi di elaborazione di 5 minuti per 
video di durata pari a 2 secondi. Questo tempo di elaborazione viene reso più tollerabile dall'esecuzione in background
del modello, che consente all'utente di utilizzare altre applicazioni o di bloccare il dispositivo nell'attesa.

\section{Sviluppi futuri}
\label{sec:sviluppi-futuri}

Data la scarsa risoluzione massima che può gestire l'applicazione al momento, la priorità
principale sta nell'aumento della risoluzione gestibile. Dato che, come già detto, il sistema è
di natura pesante e ulteriori ottimizzazioni sarebbero difficili e probabilmente poco utili, 
oltre a rischiare una grande perdita di qualità, un altro approccio possibile potrebbe essere
il trasferimento dell'elaborazione su un server, al quale l'app si connetterebbe per caricare i
video di input e dal quale riceverebbe il video elaborato. Questo approccio è usato da altre app
che offrono servizi di elaborazione immagini tramite reti neurali, specie quando questa 
elaborazione ha come risultato altre immagini.

Si potrebbero anche aggiungere, con meno priorità, ulteriori funzionalità: per esempio, un
collegamento diretto tra cattura video e elaborazione degli stessi, permettendo un workflow più
pulito da cattura ad elaborazione, evitando di dover cercare il video appena registrato nella
selezione dei file.

Inoltre, nel caso in cui si riuscisse ad ottenere un'ottimizzazione molto migliore, sarebbe 
possibile elaborare i video \emph{on the fly}, in tempo reale durante la cattura; con i tempi
attuali è impossibile, e molto lontano dall'essere realizzabile, ma non si può escludere che un
modello futuro, o in alternativa una connessione in streaming con un server sufficientemente
potente, potrebbero portare a questo risultato.